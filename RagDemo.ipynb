{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ 3GPP Spec Retrieval-Augmented Generation (RAG) App\n",
    "\n",
    "This is the **Demo of RAG implementation on the simple questions of 3GPP spec**.  \n",
    "We built a simple chatbot using an LLM (gpt-4.1) to handle user asked questions.\n",
    "\n",
    "This combines **document similarity search** with **LLM summarization**, letting you ask questions that get answered using your own internal documents.\n",
    "\n",
    "üéØ **Use case:**  \n",
    "1. Retrieve the most relevant content from uploaded document and trained model data\n",
    "2. Summarize or directly answer your question using the retrieved context\n",
    "\n",
    "By the end, you‚Äôll have a powerful mini assistant that‚Äôs grounded in your own documentation, perfect for accelerating engineering discovery and troubleshooting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Import all the required limbraries and define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json \n",
    "import base64 \n",
    "import os\n",
    "from typing import List\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "CLIENT_ID = os.environ.get(\"CISCO_CLIENT_ID\", \"<<YOUR_CLIENT_ID>>\")\n",
    "CLIENT_SECRET = os.environ.get(\"CISCO_CLIENT_SECRET\", \"<<YOUR_CLIENT_SECRET>>\")\n",
    "APP_KEY = os.environ.get(\"CISCO_APP_KEY\", \"<<YOUR_APP_KEY>>\")\n",
    "FILE_PATH = os.environ.get(\"FILE_PATH\", \"<<PATH_TO_YOUR_DOCUMENT>>\")  # Update this path to your actual document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create Function to get access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getApiKey():\n",
    "    url = 'https://id.cisco.com/oauth2/default/v1/token'\n",
    "    payload = \"grant_type=client_credentials\" \n",
    "    value = base64.b64encode(f'{CLIENT_ID}:{CLIENT_SECRET}'.encode('utf-8')).decode('utf-8') \n",
    "    headers = {\"Accept\": \"*/*\", \"Content-Type\": \"application/x-www-form-urlencoded\", \"Authorization\": f\"Basic {value}\" } \n",
    "    token_response = requests.request(\"POST\", url, headers=headers, data=payload) \n",
    "    token_data = token_response.json() \n",
    "    access_token = token_data.get('access_token')\n",
    "    return access_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Fetch and read document content from the specified file path.\n",
    "- Supports .docx, .txt, and .pdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDocument():\n",
    "    \"\"\"\n",
    "    Fetch and read document content from the specified file path.\n",
    "    Supports .docx, .txt, and .pdf files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(FILE_PATH):\n",
    "            raise FileNotFoundError(f\"File not found: {FILE_PATH}\")\n",
    "        \n",
    "        file_extension = os.path.splitext(FILE_PATH)[1].lower()\n",
    "        \n",
    "        if file_extension == '.docx':\n",
    "            # For Word documents, we need python-docx library\n",
    "            try:\n",
    "                from docx import Document\n",
    "                doc = Document(FILE_PATH)\n",
    "                content = []\n",
    "                for paragraph in doc.paragraphs:\n",
    "                    if paragraph.text.strip():  # Skip empty paragraphs\n",
    "                        content.append(paragraph.text)\n",
    "                return '\\n'.join(content)\n",
    "            except ImportError:\n",
    "                return \"Error: python-docx library is required to read .docx files. Install it with: pip install python-docx\"\n",
    "        \n",
    "        elif file_extension == '.txt':\n",
    "            # For text files\n",
    "            with open(FILE_PATH, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        \n",
    "        elif file_extension == '.pdf':\n",
    "            # For PDF files, we need PyPDF2 or similar library\n",
    "            try:\n",
    "                import PyPDF2\n",
    "                with open(FILE_PATH, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    content = []\n",
    "                    for page in pdf_reader.pages:\n",
    "                        content.append(page.extract_text())\n",
    "                    return '\\n'.join(content)\n",
    "            except ImportError:\n",
    "                return \"Error: PyPDF2 library is required to read .pdf files. Install it with: pip install PyPDF2\"\n",
    "        \n",
    "        else:\n",
    "            return f\"Error: Unsupported file format '{file_extension}'. Supported formats: .docx, .txt, .pdf\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error reading document: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Generate answer using Cisco's Azure OpenAI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Answer generation function ready!\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "def generate_answer(prompt, access_token, app_key, model=\"gpt-4.1\"):\n",
    "    \"\"\"\n",
    "    Generate answer using Cisco's Azure OpenAI endpoint\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint='https://chat-ai.cisco.com',\n",
    "            api_key=access_token,\n",
    "            api_version=\"2023-08-01-preview\"\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Answer questions based on the provided context.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            user=f'{{\"appkey\": \"{app_key}\"}}',\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        #return response.choices[0].message.content.strip()\n",
    "        #return response.choices[0].message\n",
    "        print(response.choices[0].message.content.strip())\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return \"Sorry, I couldn't generate an answer at this time.\"\n",
    "\n",
    "print(\"‚úÖ Answer generation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : A simple RAG-like function that retrieves the most relevant sentences from the document based on keyword overlap with the question, and returns them as the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rag_qa(document: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple RAG-like function that retrieves the most relevant sentences from the document\n",
    "    based on keyword overlap with the question, and returns them as the answer.\n",
    "\n",
    "    Args:\n",
    "        document (str): The document content to search.\n",
    "        question (str): The user's question.\n",
    "\n",
    "    Returns:\n",
    "        str: Concatenated relevant sentences as the answer.\n",
    "    \"\"\"\n",
    "    # Split document into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', document)\n",
    "    question_words = set(re.findall(r'\\w+', question.lower()))\n",
    "    \n",
    "    # Score each sentence by keyword overlap\n",
    "    scored = []\n",
    "    for sent in sentences:\n",
    "        sent_words = set(re.findall(r'\\w+', sent.lower()))\n",
    "        overlap = len(question_words & sent_words)\n",
    "        if overlap > 0:\n",
    "            scored.append((overlap, sent))\n",
    "    \n",
    "    # Sort by overlap score, descending\n",
    "    scored.sort(reverse=True)\n",
    "    top_sentences = [s for _, s in scored[:]]\n",
    "    \n",
    "    if not top_sentences:\n",
    "        return \"Sorry, I couldn't find relevant information in the document.\"\n",
    "    return \" \".join(top_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Calls the simple_rag_qa function with the provided question and prints the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_document_question(question: str):\n",
    "    \"\"\"\n",
    "    Calls the simple_rag_qa function with the provided question and prints the answer.\n",
    "    \"\"\"\n",
    "    document_content = fetchDocument()\n",
    "    print(len(document_content))\n",
    "    answer = simple_rag_qa(document_content, question)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Create the Prompt for LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, chunks):\n",
    "    context = \"\\n\".join(chunks)\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    print(\"Prompt created successfully.\")\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : üöÄ RAG QUESTION PROCESSING\n",
    "- This takes user input and based on that it generates the output\n",
    "- \"What is eDRX in ULR and it's call flow?\"  # Example question, replace with your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Token: eyJraWQiOiJIUXh2eW4zM3VOSEVQMFd1RUZiNFpMTW9nZzFnMDhTRnJQM2haQ0g3cjJRIiwiYWxnIjoiUlMyNTYifQ.eyJ2ZXIiOjEsImp0aSI6IkFULklpd1FWaC1rSmRxc3FDNEVQLWlnRlpmb3NVeTFGNXpQbTA4X0RQeWxYUXMiLCJpc3MiOiJodHRwczovL2lkLmNpc2NvLmNvbS9vYXV0aDIvZGVmYXVsdCIsImF1ZCI6ImFwaTovL2RlZmF1bHQiLCJpYXQiOjE3NTM3MDQ3MTgsImV4cCI6MTc1MzcwODMxOCwiY2lkIjoiMG9hcG0weThqcGFJSWtvamM1ZDciLCJzY3AiOlsiY3VzdG9tc2NvcGUiXSwic3ViIjoiMG9hcG0weThqcGFJSWtvamM1ZDciLCJhenAiOiIwb2FwbTB5OGpwYUlJa29qYzVkNyJ9.mxiHsjIWXBZWn9vJHYPjaWHVkpX0iQd8VSWH5JmGJcqjRtcaNSe_L2Yq3DRgZDqe7iobTeGnKzquXXH_OFgY988QFHKozN0gz4Vu60Rz5G4RYNpjQ7ZmeyFXVeXS_G0gBcEpx1_LbFKHQFHJuZb9LNsCyuONqVi2UjmLF0QserqDGkl2kr2-tRg0fUBq1IEXK-9KUwCSdBdL71tG8bsqh1YhlMCbjmmmoJsFvkDsjzvDhN5xMH067pGC9taX-OTdOnTsymDwYK8A7MjHC2NRvx7ikIfPguiEIgwlyUlwesppvwtOf25MgbxlyaoWoQj_Wbq8VbF8SqEOD14qPFl-Cg\n",
      "Access token retrieved successfully!\n",
      "\n",
      "üîç Step 1: Retrieving relevant content...\n",
      "9198\n",
      "Found 2722 relevant chunks\n",
      "\n",
      "Step 2: Creating prompt...\n",
      "Prompt created successfully.\n",
      "\n",
      "Step 3: Generating answer (this may take a few seconds)...\n",
      "Certainly! Here is an explanation of eDRX (Extended Discontinuous Reception) in the context of a typical LTE/4G call flow, specifically focusing on how it is handled between network elements like MME and HSS, according to the context you provided:\n",
      "\n",
      "### eDRX with Call Flow\n",
      "\n",
      "#### What is eDRX?\n",
      "- eDRX (Extended Discontinuous Reception) is a power-saving feature designed for IoT (Internet of Things) devices in LTE/4G networks. It allows devices to \"sleep\" for extended periods, reducing battery consumption by not listening for downlink data as frequently.\n",
      "\n",
      "#### Key Network Elements\n",
      "- **UE (User Equipment)**: The device (e.g., IoT sensor).\n",
      "- **MME (Mobility Management Entity)**: Controls signaling and session management in LTE.\n",
      "- **HSS (Home Subscriber Server)**: Stores subscriber data, including eDRX configuration.\n",
      "\n",
      "#### The Call Flow: How eDRX is Exchanged\n",
      "\n",
      "1. **Initial Attach/Connection**\n",
      "   - The **UE** initiates a connection to the LTE network via radio access (E-UTRAN).\n",
      "   - The **MME** receives the Attach Request from the UE.\n",
      "\n",
      "2. **Update Location Request (ULR)**\n",
      "   - The **MME** sends an **Update Location Request (ULR)** message to the **HSS** over the S6a interface.\n",
      "   - The **ULR** includes information such as the subscriber's IMSI and the **RAT-Type** (Radio Access Technology, e.g., EUTRAN for LTE).\n",
      "   - **Note:** The ULR does **not** carry eDRX values from the MME.\n",
      "\n",
      "3. **HSS Determines eDRX Configuration**\n",
      "   - The **HSS** checks the subscriber's profile for eDRX configuration.\n",
      "   - If there are multiple possible eDRX values for a given service (e.g., DATA_4G), the HSS selects the most appropriate or preferred eDRX-Cycle-Length based on its internal logic and the RAT-Type received.\n",
      "\n",
      "4. **Update Location Answer (ULA)**\n",
      "   - The **HSS** responds to the MME with an **Update Location Answer (ULA)**.\n",
      "   - The ULA includes the **eDRX-Cycle-Length** value(s) in a specific AVP (Attribute Value Pair).\n",
      "   - Only **one** eDRX cycle length is sent per RAT-Type (e.g., one for EUTRAN, one for NB-IoT, etc.).\n",
      "\n",
      "5. **MME Applies eDRX Configuration**\n",
      "   - The **MME** uses the eDRX value received from the HSS to configure the UE's eDRX cycle as part of the session setup.\n",
      "   - The MME may pass this to the eNodeB or directly to the UE, depending on the procedure.\n",
      "\n",
      "#### Summary Table\n",
      "\n",
      "| Step         | Message         | Direction        | eDRX Info?              |\n",
      "|--------------|-----------------|------------------|-------------------------|\n",
      "| 1. Attach    | Attach Request  | UE ‚Üí MME         | No                      |\n",
      "| 2. ULR       | ULR (S6a)       | MME ‚Üí HSS        | No                      |\n",
      "| 3. Selection | (Internal)      | HSS              | HSS selects eDRX config |\n",
      "| 4. ULA       | ULA (S6a)       | HSS ‚Üí MME        | Yes (eDRX value in AVP) |\n",
      "| 5. Config    | Context Setup   | MME ‚Üî UE/eNB     | MME applies eDRX        |\n",
      "\n",
      "#### Important Notes\n",
      "- The eDRX configuration is **not** sent in the ULR, but only in the ULA from HSS to MME.\n",
      "- The HSS makes the selection of which eDRX cycle length to use if multiple are provisioned.\n",
      "- Only a **single** eDRX cycle length per RAT-Type is sent to the MME.\n",
      "- This process is part of the initial attach and session setup flow in LTE networks.\n",
      "\n",
      "#### Use Case Example\n",
      "- An IoT device attaches to the network.\n",
      "- The MME queries the HSS for the subscriber's profile and eDRX settings.\n",
      "- The HSS sends back the appropriate eDRX configuration for 4G (EUTRAN) in the ULA.\n",
      "- The device is then configured to use this eDRX cycle, enabling it to save power by sleeping for longer intervals.\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "In the LTE call flow, eDRX configuration is provisioned in the subscriber's profile on the HSS. During the attach, the MME requests the profile using a ULR, and the HSS responds with a ULA that includes the eDRX value. The MME\n",
      "\n",
      "Total time for this question: 11.67 seconds\n",
      "\n",
      "Want to ask another question? Go back to the previous cell, change the question, and run both cells again!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üöÄ RAG QUESTION PROCESSING\n",
    "# Run this cell after changing your question in the previous cell.\n",
    "# code to take input from the user\n",
    "# user_question = \"What is eDRX in ULR?\"  # Example question, replace with your own\n",
    "user_question = input(\"Enter your question about the document: \")\n",
    "access_token = getApiKey()\n",
    "print(\"Access token retrieved successfully!\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Step 1: Retrieve relevant chunks\n",
    "    print(\"\\nüîç Step 1: Retrieving relevant content...\")\n",
    "    chunks = ask_document_question(user_question)\n",
    "    print(f\"Found {len(chunks)} relevant chunks\")\n",
    "    \n",
    "    # Step 2: Create prompt\n",
    "    print(\"\\nStep 2: Creating prompt...\")\n",
    "    prompt = create_prompt(user_question, chunks)\n",
    "\n",
    "    # Step 3: Generate answer\n",
    "    print(\"\\nStep 3: Generating answer (this may take a few seconds)...\")\n",
    "    answer = generate_answer(prompt, access_token, APP_KEY)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nTotal time for this question: {elapsed:.2f} seconds\")\n",
    "    print(\"\\nWant to ask another question? Go back to the previous cell, change the question, and run both cells again!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing question: {e}\")\n",
    "    print(\"Make sure you've run the setup cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
